{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import re\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int = pd.read_csv('Interactions-3.csv')\n",
    "items = pd.read_csv(\"items_with_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int[\"page_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Int = Int.merge(items[[\"picture_url\", \"text\"]].drop_duplicates(), on=[\"picture_url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def rec_imaging(product_ids, content_dict, measure=None, top_n=5):\n",
    "    picture_urls = [content_dict[i] for i in product_ids]\n",
    "    cnt = 0\n",
    "    for idx, chunk in enumerate(chunks(picture_urls, top_n)):\n",
    "        fig = plt.figure(figsize=(20, 4))\n",
    "        for n, i in enumerate(chunk):\n",
    "            try:\n",
    "                r = requests.get(i)\n",
    "                im = Image.open(BytesIO(r.content))\n",
    "\n",
    "            except:\n",
    "                print('Something went wrong with {url}'.format(url=i))\n",
    "                continue\n",
    "\n",
    "            a = fig.add_subplot(1, top_n, n + 1)\n",
    "            if measure is not None:\n",
    "                a.title.set_text(\"measure = {}\".format(np.round(measure[cnt], 4)))\n",
    "                cnt += 1\n",
    "            plt.imshow(im)\n",
    "            plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Холодный старт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Самые популярные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Top():\n",
    "    def __init__(self, Int):\n",
    "        self.product_id_to_url = {}\n",
    "        for i in Int[[\"product_id\", \"picture_url\"]].drop_duplicates().values:\n",
    "            self.product_id_to_url[i[0]] = i[1]\n",
    "        self.interactions = Int\n",
    "        \n",
    "    def top_items(self):\n",
    "        \n",
    "        rec_imaging(items[\"product_id\"].values, self.product_id_to_url, items[\"vid\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Top(Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T.top_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cовстречаемость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recomendations():\n",
    "    def __init__(self, Int):\n",
    "        self.product_id_to_url = {}\n",
    "        for i in Int[[\"product_id\", \"picture_url\"]].drop_duplicates().values:\n",
    "            self.product_id_to_url[i[0]] = i[1]\n",
    "        self.interactions = Int\n",
    "        \n",
    "    def coocurrency_count(self):\n",
    "        Int = self.interactions[[\"vid\", \"product_id\"]].drop_duplicates()\n",
    "        user_products = Int.groupby([\"vid\"])[\"product_id\"].apply(list).reset_index()\n",
    "        product_num = [len(i) for i in user_products[\"product_id\"]]\n",
    "        user_products[\"prod_num\"] = product_num\n",
    "        user_products = user_products[user_products[\"prod_num\"] > 1]\n",
    "        \n",
    "        cooc = {}\n",
    "        for i in tqdm.tqdm_notebook(user_products.values):\n",
    "            for j in range(len(i[1])):\n",
    "                for k in range(len(i[1])):\n",
    "                    if j != k:\n",
    "                        try:\n",
    "                            cooc[str(i[1][j]) + \"_\" + str(i[1][k])] += 1\n",
    "                        except:\n",
    "                            cooc[str(i[1][j]) + \"_\" + str(i[1][k])] = 1\n",
    "        cooc_list = []\n",
    "        for i, j in cooc.items():\n",
    "            if j != 1:\n",
    "                cooc_list.append(i.split(\"_\") + [j])\n",
    "        self.cooc_rec = pd.DataFrame(cooc_list, columns=[\"item1\", \"item2\", \"measure\"])\n",
    "    \n",
    "    def get_rec(self, i, show=False):\n",
    "        recs = self.cooc_rec[self.cooc_rec[\"item1\"] == str(i)]\\\n",
    "                            .sort_values(\"measure\", ascending=False)\\\n",
    "                            .head(10)\n",
    "        print(u\"Для товара\")\n",
    "        rec_imaging([i], self.product_id_to_url)\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging(recs[\"item2\"].values.astype(int), self.product_id_to_url, \n",
    "                         recs[\"measure\"].values.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec = Recomendations(Int)\n",
    "cooc_rec.coocurrency_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1362)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(3453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(3445)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(1212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooc_rec.get_rec(631)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Content_Based():\n",
    "    def __init__(self, items, interactions):\n",
    "        self.items = items\n",
    "        self.interactions = interactions\n",
    "        self.content_dict = {}\n",
    "        for i, j in enumerate(items[\"picture_url\"]):\n",
    "            self.content_dict[i] = j\n",
    "        self.inversed_dict = {v: k for k, v in self.content_dict.items()}\n",
    "        \n",
    "    def avg_feature_vector(self, words, model, num_features, index2word_set):\n",
    "        feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "        n_words = 0\n",
    "        for word in words:\n",
    "            if word in index2word_set:\n",
    "                n_words += 1\n",
    "                feature_vec = np.add(feature_vec, model.wv[word])\n",
    "        if (n_words > 0):\n",
    "            feature_vec = feature_vec / n_words\n",
    "        return feature_vec\n",
    "\n",
    "    def get_items_representation(self):\n",
    "        \n",
    "        item_description = [gensim.utils.simple_preprocess(re.sub(\"[^a-zA-Zа-яА-Я]+\", \" \", i.lower())) \n",
    "                            for i in self.items['text']]\n",
    "        #build vocabulary and train model\n",
    "        self.model = gensim.models.Word2Vec(\n",
    "                item_description,\n",
    "                size=200,\n",
    "                window=10,\n",
    "                min_count=1,\n",
    "                workers=10,\n",
    "                iter=100)\n",
    "        self.index2word_set = set(self.model.wv.index2word)\n",
    "        self.items_embs = np.zeros((len(item_description), 200))\n",
    "        for i in range(self.items_embs.shape[0]):\n",
    "            self.items_embs[i] = self.avg_feature_vector(item_description[i], self.model, 200, self.index2word_set)\n",
    "        \n",
    "        \n",
    "    def get_rec_I2I(self, i):\n",
    "        metrics = cosine_similarity([self.items_embs[i]], self.items_embs)\n",
    "        print(u\"Для товара\")\n",
    "        rec_imaging([i], self.content_dict)\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging(np.argsort(metrics)[0][::-1][1:11], self.content_dict, np.sort(metrics)[0][::-1][1:11])\n",
    "\n",
    "\n",
    "    def get_rec_U2I(self, i):\n",
    "        ui = self.interactions[self.interactions[\"vid\"] == i]\n",
    "        user_vector = \" \".join(ui[\"text\"])\n",
    "        user_processed = gensim.utils.simple_preprocess(re.sub(\"[^a-zA-Zа-яА-Я]+\", \" \", user_vector.lower()))\n",
    "        user_emb = self.avg_feature_vector(user_processed, self.model, 200, self.index2word_set)\n",
    "        metrics = cosine_similarity([user_emb], self.items_embs)\n",
    "        print(u\"Для пользователя, который взаимодействовал с товарами\")\n",
    "        rec_imaging(np.unique([self.inversed_dict[i] for i in ui[\"picture_url\"]]), self.content_dict)\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging(np.argsort(metrics)[0][::-1][1:11], self.content_dict, np.sort(metrics)[0][::-1][1:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB = Content_Based(items, Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_items_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_rec_I2I(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_rec_I2I(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_rec_U2I(3212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_rec_U2I(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_rec_U2I(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CB.get_rec_U2I(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class W2V_REC():\n",
    "    def __init__(self, interactions):\n",
    "        self.interactions = interactions\n",
    "        self.interactions[\"product_id\"] = self.interactions[\"product_id\"].astype(str)\n",
    "        self.content_dict = {}\n",
    "        for i, j in interactions[[\"product_id\", \"picture_url\"]].drop_duplicates().values:\n",
    "            self.content_dict[i] = j\n",
    "\n",
    "    def get_w2v(self):\n",
    "        interactions_sentences = self.interactions.groupby([\"vid\"])[\"product_id\"].apply(list).reset_index()\n",
    "        self.model = gensim.models.Word2Vec(\n",
    "                                        interactions_sentences[\"product_id\"].apply(list).values,\n",
    "                                        size=200,\n",
    "                                        window=10,\n",
    "                                        min_count=1,\n",
    "                                        workers=10,\n",
    "                                        iter=100)\n",
    "        self.index2word_set = set(self.model.wv.index2word)\n",
    "        \n",
    "    def avg_feature_vector(self, words):\n",
    "        feature_vec = np.zeros(200, dtype='float32')\n",
    "        n_words = 0\n",
    "        for word in words:\n",
    "            if word in self.index2word_set:\n",
    "                n_words += 1\n",
    "                feature_vec = np.add(feature_vec, self.model.wv[word])\n",
    "        if (n_words > 0):\n",
    "            feature_vec = feature_vec / n_words\n",
    "        return feature_vec\n",
    "    \n",
    "    def get_rec_I2I(self, i):\n",
    "        metrics = [j[1] for j in self.model.wv.similar_by_word(i)]\n",
    "        items = [j[0] for j in self.model.wv.similar_by_word(i)]\n",
    "        print(u\"Для товара\")\n",
    "        r = requests.get(self.content_dict[i])\n",
    "        im = Image.open(BytesIO(r.content))\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging(items, self.content_dict, metrics)\n",
    "\n",
    "    def get_rec_U2I(self, i):\n",
    "        user_items = list(self.interactions[self.interactions[\"vid\"] == i][\"product_id\"].drop_duplicates())\n",
    "        user_emb = self.avg_feature_vector(user_items)\n",
    "        recs = self.model.wv.most_similar(positive=[user_emb], topn=10)\n",
    "        metrics = [j[1] for j in recs]\n",
    "        items = [j[0] for j in recs]\n",
    "        print(u\"Для пользователя, который взаимодействовал с товарами\")\n",
    "        rec_imaging(user_items, self.content_dict)\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging(items, self.content_dict, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = W2V_REC(Int)\n",
    "w.get_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.get_rec_I2I(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.get_rec_I2I(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.get_rec_U2I(2122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.get_rec_U2I(4322)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user = 121\n",
    "CB.get_rec_U2I(user)\n",
    "w.get_rec_U2I(user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colloborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weights = pd.DataFrame({\"page_type\": [\"PRODUCT\", \"CART\", \"PURCHASE\"],\n",
    "                           'weight': [1, 1, 1]})\n",
    "weighted = Int.merge(df_weights, on=\"page_type\")\\\n",
    "                  .groupby([\"vid\", \"product_id\", \"picture_url\"])[\"weight\"]\\\n",
    "                  .sum()\\\n",
    "                  .reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted[\"weight\"] = (weighted[\"weight\"] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_rates = coo_matrix((weighted[\"weight\"], (weighted[\"vid\"], weighted[\"product_id\"])), \n",
    "                    shape=(len(set(weighted[\"vid\"])), len(set(weighted[\"product_id\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rates = csr_rates.getrow(12).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity([user_rates], csr_rates).reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rates = csr_rates.getrow(idx).toarray()[0]\n",
    "watched_items = np.where(user_rates != 0)[0]\n",
    "metrics = cosine_similarity([user_rates], csr_rates).reshape(-1, 1)\n",
    "# домножаем оценки пользователя на коэффициент похожести\n",
    "rates = csr_matrix.multiply(csr_rates.copy(), metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_rates.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colloborative():\n",
    "    def __init__(self, interactions):\n",
    "        self.content_dict = {}\n",
    "        for i, j in interactions[[\"product_id\", \"picture_url\"]].drop_duplicates().values:\n",
    "            self.content_dict[int(i)] = j\n",
    "        df_weights = pd.DataFrame({\"page_type\": [\"PRODUCT\", \"CART\", \"PURCHASE\"],\n",
    "                                   'weight': [1, 1, 1]})\n",
    "        weighted = interactions.merge(df_weights, on=\"page_type\")\\\n",
    "                          .groupby([\"vid\", \"product_id\", \"picture_url\"])[\"weight\"]\\\n",
    "                          .sum()\\\n",
    "                          .reset_index()\n",
    "        weighted[\"weight\"] = (weighted[\"weight\"] > 0).astype(int)\n",
    "        self.csr_rates = coo_matrix((weighted[\"weight\"], (weighted[\"vid\"], weighted[\"product_id\"])), \n",
    "                            shape=(len(set(weighted[\"vid\"])), len(set(weighted[\"product_id\"]))))\n",
    "        \n",
    "\n",
    "    def user_based(self, idx):\n",
    "        # считаем косинус между пользователем idx и всеми пользователями\n",
    "        user_rates = self.csr_rates.getrow(idx).toarray()[0]\n",
    "        watched_items = np.where(user_rates != 0)[0]\n",
    "        metrics = cosine_similarity([user_rates], self.csr_rates).reshape(-1, 1)\n",
    "        # домножаем оценки пользователя на коэффициент похожести\n",
    "        rates = csr_matrix.multiply(self.csr_rates.copy(), metrics)\n",
    "        # чтобы не рекомендовать уже просмотренные - зануляем веса просмотренных\n",
    "        total_rate = (1 - user_rates.astype(bool)) * np.array(np.sum(rates, axis=0))[0]\n",
    "        # печатаем рекомендации\n",
    "        self.get_rec(watched_items, np.arange(self.csr_rates.shape[1])[np.argsort(total_rate)[::-1][:10]],\n",
    "                    np.sort(total_rate)[::-1][:10])\n",
    "        \n",
    "    def item_based(self, idx):\n",
    "        # считаем косинус между пользователем idx и всеми пользователями\n",
    "        item_rates = self.csr_rates.getcol(idx).toarray().reshape(1, -1)\n",
    "        metrics = cosine_similarity(item_rates, self.csr_rates.T).reshape(-1, 1)\n",
    "        # домножаем оценки пользователя на коэффициент похожести\n",
    "        rates = csr_matrix.multiply(self.csr_rates.T.copy(), metrics)\n",
    "        total_rate = np.array(np.sum(rates, axis=1)).ravel()\n",
    "        # печатаем рекомендации\n",
    "        self.get_rec([idx], np.arange(self.csr_rates.shape[1])[np.argsort(total_rate)[::-1][:10]],\n",
    "                    np.sort(total_rate)[::-1][:10])\n",
    "\n",
    "    def get_rec(self, watched, recs, measure):\n",
    "        print(u\"Для таких товаров\")\n",
    "        rec_imaging([i for i in watched], self.content_dict)\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging([i for i in recs], self.content_dict, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clb = Colloborative(Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.item_based(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.item_based(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.item_based(31211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.item_based(2556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(34434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(77777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clb.user_based(323)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, interactions, k):\n",
    "        interactions[\"product_id\"] = interactions[\"product_id\"].astype(int)\n",
    "        self.k = k\n",
    "        self.content_dict = {}\n",
    "        for i, j in interactions[[\"product_id\", \"picture_url\"]].drop_duplicates().values:\n",
    "            self.content_dict[i] = j\n",
    "        df_weights = pd.DataFrame({\"page_type\": [\"PRODUCT\", \"CART\", \"PURCHASE\"],\n",
    "                                   'weight': [1, 1, 1]})\n",
    "        weighted = interactions.merge(df_weights, on=\"page_type\")\\\n",
    "                          .groupby([\"vid\", \"product_id\", \"picture_url\"])[\"weight\"]\\\n",
    "                          .sum()\\\n",
    "                          .reset_index()\n",
    "        weighted[\"weight\"] = (weighted[\"weight\"] > 0).astype(int)\n",
    "        self.csr_rates = coo_matrix((weighted[\"weight\"], (weighted[\"vid\"], weighted[\"product_id\"])), \n",
    "                            shape=(len(set(weighted[\"vid\"])), len(set(weighted[\"product_id\"]))))\n",
    "        \n",
    "    def MF(self):\n",
    "        U, S, V = svds(self.csr_rates.astype(float), k=self.k)\n",
    "        self.user_embs = U\n",
    "        self.items_embs = V.T\n",
    "        \n",
    "    def LightFM(self):\n",
    "        self.model = LightFM(loss='warp', no_components=100, learning_rate=0.03, learning_schedule=\"adadelta\")\n",
    "        self.model.fit(self.csr_rates, epochs=5, num_threads=40, verbose=True)\n",
    "        self.user_feature_bias, self.user_feature_embeddings = self.model.get_user_representations()\n",
    "        self.item_feature_bias, self.items_embs = self.model.get_item_representations()\n",
    "\n",
    "    def get_rec(self, i):\n",
    "        metrics = cosine_similarity([self.items_embs[i]], self.items_embs)\n",
    "        print(u\"Для товара\")\n",
    "        rec_imaging([i], self.content_dict)\n",
    "        print(u\"Такие рекомендации\")\n",
    "        rec_imaging(np.argsort(-metrics)[0][1:11], self.content_dict, -np.round(np.sort(-metrics)[0][1:11], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_svd = MatrixFactorization(Int, 30)\n",
    "simple_svd.MF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_svd.get_rec(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_svd.get_rec(1002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_svd.get_rec(10022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_svd.get_rec(12342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf = MatrixFactorization(Int, 300)\n",
    "mf.LightFM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.get_rec(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf.get_rec(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data contains the book rating information. Ratings (Book-Rating) are either explicit, expressed on a scale from 1-10 (higher values denoting higher appreciation), or implicit, expressed by 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Реализовать персональный топ  - принимает на вход пол и локацию, на выходе персональный топ   - 1 балл\n",
    "\n",
    "Персональный топ - это топ товаров по похожим возрасту/интересам/локации. Как сделать? Разбить на сегменты по выбраным признакам. Топ делать по книгам с хорошим средним рейтингом.\n",
    "\n",
    "### 2. На основе метода кластеризации похожих пользователей построить рекомендации (Слайд 25) - 2 балла\n",
    "\n",
    "Нужно топ-10 рекомендаций с самой высокой оценкой. Считаем среднюю оценку для каждой книги по кластеру и выводим топ-10 книг.\n",
    "\n",
    "### 3. Применить методы расмотренные на лекции (Совстречаемость - 2 балл, Content-based - 1 балл, Коллаборативная фильтрация - 3 балла , Матричная Факторизация - 1 балл) - 7 баллов\n",
    "\n",
    "В совстречаемости также учитывать оценки. Вес пары книг встретившихся у пользователя - полусумма их оценок\n",
    "\n",
    "Коллаборативную фильтрацию реализовывать как на слайде 50 презентации, посоветовав каждому пользователю топ-10 книг с самой высокой оценкой. Сделать рекомендации User-based и Item-based и сравнить.\n",
    "\n",
    "Если совсем сложно - можно сделать как в семинарской части, поставив оценку \"0\", если рейтинг < 5 и \"1\" - в противном случае. Тогда максимум за это - 1 балл.\n",
    "\n",
    "Для Content-based, Коллаборативной фильтрации, Матричной Факторизации реализовать U2I и I2I рекомендации\n",
    "\n",
    "### Примечание:\n",
    "\n",
    "Так как пользователей много - можно зафиксировать несколько произвольных и для них уже составлять рекомендации\n",
    "Работоспособность I2I можно проверять на известных книгах (Гарри Поттер, Властелин Колец, Интервью с вампиром, Код-Да-Винчи, Маленький Принц)\n",
    "Рейтинг книг обязательно нужно учитывать\n",
    "\n",
    "Не забываем также предобработать данные - выкинуть выбросы-пользователей и выбросы-книги.\n",
    "\n",
    "# Дедлайн 30 ноября\n",
    "# Жесткий дедлайн - 7 декабря\n",
    "\n",
    "Выводить в качестве рекомендаций лучше названия книг, картинки (если они есть) и соответствующие метрики близости.\n",
    "Присылать в виде ноутбука\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"BX-Books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = pd.read_csv(\"BX-Book-Ratings.csv\", sep=\";\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions[interactions[\"Book-Rating\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_meets = interactions.groupby(\"ISBN\")[\"User-ID\"].count().reset_index().rename(columns={\"User-ID\": \"user_num\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_meets = interactions.groupby(\"User-ID\")[\"ISBN\"].count().reset_index().rename(columns={\"ISBN\": \"books_num\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions.merge(books_meets, on=[\"ISBN\"]).merge(user_meets, on=[\"User-ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions[(interactions[\"user_num\"] > 5) & \n",
    "                            (interactions[\"books_num\"] > 5) &\n",
    "                            (interactions[\"books_num\"] < 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('BX-Users.csv', delimiter=';', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions.merge(books[[\"ISBN\", \"Image-URL-M\", \"Book-Title\"]].rename(\n",
    "    columns={\"Image-URL-M\": \"picture_url\"}), on=[\"ISBN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions[\"product_id\"] = le.fit_transform(interactions[\"ISBN\"])\n",
    "interactions[\"vid\"] = le.fit_transform(interactions[\"User-ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csr_rates = coo_matrix((interactions[\"Book-Rating\"], (interactions[\"vid\"], interactions[\"product_id\"])), \n",
    "                            shape=(len(set(interactions[\"vid\"])), len(set(interactions[\"product_id\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ищем id нужных книг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in interactions[[\"product_id\", \"Book-Title\"]].drop_duplicates().values:\n",
    "    if \"David Copperfield\" in j:\n",
    "        print(\"idx:\", i, \"\\tBook Title:\", j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
